# ğŸ§  VQA Dataset Project

This project aims to build a multilingual, multi-domain Visual Question Answering (VQA) dataset. It is structured on a rich taxonomy, populated with images from rare and underutilized sources, and annotated with high-quality visual reasoning questions.

---

## ğŸ” Data Sourcing Philosophy

Unlike generic scraping from Google or Bing, we focus on:
- Academic journals and institutional archives
- Language-specific content (Arabic, Korean, Japanese, etc.)
- Open government repositories
- Niche forums and deep search platforms (Windsurf, Cursor, DeepSearch)

Each image must:
- Contain text **within the image**
- Avoid watermarks or copyright issues
- Be visually and semantically relevant to the assigned domain/subdomain

---

## ğŸ—‚ï¸ Project Structure
vqa_dataset_project/
â”œâ”€â”€ raw_images/                 # Downloaded images by domain/subdomain
â”‚   â””â”€â”€ [domain]/[subdomain]/[theme]/image.jpg
â”œâ”€â”€ metadata/                  # Taxonomy & image metadata
â”‚   â””â”€â”€ taxonomy_structure.json
â”œâ”€â”€ qa_data/                   # VQA JSONL outputs
â”‚   â””â”€â”€ [domain]_[subdomain].jsonl
â”œâ”€â”€ scripts/                   # Scraper & processing tools
â”‚   â”œâ”€â”€ image_scraper.py
â”‚   â”œâ”€â”€ generate_metadata.py
â”œâ”€â”€ README.md

---

## ğŸ“„ JSONL Output Format

Each image entry includes 5 diverse reasoning questions:
- Object recognition
- Causal/logical inference
- Intermodal (e.g., MRI, satellite)
- Color-based reasoning
- Spatial awareness

```json
{
  "image_id": "medical_001",
  "image_path": "images/medicine/radiology/brain_scan/medical_001.jpg",
  "domain": "medicine",
  "subdomain": "radiology",
  "theme": "brain_scan",
  "language": "en",
  "image_metadata": {
    "width": 1024,
    "height": 768,
    "format": "JPEG"
  },
  "questions": [
    {
      "question": "What part of the brain is shown?",
      "answer": "Frontal lobe",
      "type": "object_recognition",
      "difficulty": "medium"
    }
    // ...4 more types
  ]
}